{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "contrary-bangladesh",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/csci8523/ganta016/.local/lib/python3.8/site-packages/pandas/core/computation/expressions.py:20: UserWarning: Pandas requires version '2.7.3' or newer of 'numexpr' (version '2.7.1' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n"
     ]
    }
   ],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from skimage.io import imread, imsave\n",
    "\n",
    "from keras import applications\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Activation, Dense, Dropout, Flatten, GlobalAveragePooling2D\n",
    "from keras.utils import to_categorical\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import Model\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "altered-award",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_dir = os.path.join('brazilian_coffee_dataset', 'Images')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "worthy-afternoon",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = os.listdir(source_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "respected-assistant",
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_model = applications.InceptionV3(include_top=False, weights=None)\n",
    "pretrained_model.trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "graphic-bracket",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2876 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "image_data_generator = ImageDataGenerator(rescale=1/255.0)\n",
    "image_generator = image_data_generator.flow_from_directory(source_dir,\n",
    "                                                        batch_size=64,\n",
    "                                                        shuffle=False\n",
    "                                                        )\n",
    "count = 0\n",
    "X_batches, Y_batches = [], []\n",
    "for X, Y in image_generator:\n",
    "    X_batches.append(X)\n",
    "    Y_batches.append(Y)\n",
    "    count += X.shape[0]\n",
    "    if count >= image_generator.n:\n",
    "        break\n",
    "\n",
    "x_data = np.concatenate(X_batches)\n",
    "y_data = np.concatenate(Y_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "intellectual-shoot",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_val, y_train, y_val = train_test_split(x_data, y_data, test_size = 0.4, random_state=101)\n",
    "x_test, x_val, y_test, y_val = train_test_split(x_val, y_val, test_size = 0.5, random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fitting-negotiation",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = pretrained_model.input\n",
    "pooling_layer = GlobalAveragePooling2D()(pretrained_model.output)\n",
    "drop_layer = Dropout(0.20)(pooling_layer)\n",
    "x_layer = Dense(256, activation='relu')(drop_layer)\n",
    "drop_layer1 = Dropout(0.5)(x_layer)\n",
    "outputs = Dense(len(labels), activation='softmax')(drop_layer1)\n",
    "\n",
    "model = Model(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "yellow-irish",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/csci8523/ganta016/.local/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/80\n",
      "27/27 - 154s - loss: 0.6877 - accuracy: 0.7154 - val_loss: 0.8053 - val_accuracy: 0.3628 - 154s/epoch - 6s/step\n",
      "Epoch 2/80\n",
      "27/27 - 138s - loss: 0.4725 - accuracy: 0.8267 - val_loss: 0.9126 - val_accuracy: 0.5712 - 138s/epoch - 5s/step\n",
      "Epoch 3/80\n",
      "27/27 - 141s - loss: 0.5232 - accuracy: 0.8272 - val_loss: 1.1648 - val_accuracy: 0.5955 - 141s/epoch - 5s/step\n",
      "Epoch 4/80\n",
      "27/27 - 138s - loss: 0.4971 - accuracy: 0.8058 - val_loss: 1.3998 - val_accuracy: 0.5712 - 138s/epoch - 5s/step\n",
      "Epoch 5/80\n",
      "27/27 - 140s - loss: 0.4351 - accuracy: 0.8412 - val_loss: 2.2797 - val_accuracy: 0.5729 - 140s/epoch - 5s/step\n",
      "Epoch 6/80\n",
      "27/27 - 138s - loss: 0.3661 - accuracy: 0.8522 - val_loss: 1.9769 - val_accuracy: 0.5642 - 138s/epoch - 5s/step\n",
      "Epoch 7/80\n",
      "27/27 - 139s - loss: 0.3519 - accuracy: 0.8533 - val_loss: 2.3199 - val_accuracy: 0.5885 - 139s/epoch - 5s/step\n",
      "Epoch 8/80\n",
      "27/27 - 140s - loss: 0.3369 - accuracy: 0.8696 - val_loss: 1.3170 - val_accuracy: 0.6250 - 140s/epoch - 5s/step\n",
      "Epoch 9/80\n",
      "27/27 - 139s - loss: 0.3204 - accuracy: 0.8875 - val_loss: 1.3251 - val_accuracy: 0.5729 - 139s/epoch - 5s/step\n",
      "Epoch 10/80\n",
      "27/27 - 136s - loss: 0.3218 - accuracy: 0.8806 - val_loss: 1.5285 - val_accuracy: 0.5816 - 136s/epoch - 5s/step\n",
      "Epoch 11/80\n",
      "27/27 - 142s - loss: 0.2915 - accuracy: 0.8777 - val_loss: 1.5461 - val_accuracy: 0.5764 - 142s/epoch - 5s/step\n",
      "Epoch 12/80\n",
      "27/27 - 144s - loss: 0.2986 - accuracy: 0.8881 - val_loss: 0.8417 - val_accuracy: 0.7083 - 144s/epoch - 5s/step\n",
      "Epoch 13/80\n",
      "27/27 - 143s - loss: 0.2852 - accuracy: 0.8817 - val_loss: 0.8494 - val_accuracy: 0.7101 - 143s/epoch - 5s/step\n",
      "Epoch 14/80\n",
      "27/27 - 143s - loss: 0.2673 - accuracy: 0.8939 - val_loss: 0.6305 - val_accuracy: 0.7517 - 143s/epoch - 5s/step\n",
      "Epoch 15/80\n",
      "27/27 - 143s - loss: 0.2672 - accuracy: 0.8928 - val_loss: 0.4497 - val_accuracy: 0.7986 - 143s/epoch - 5s/step\n",
      "Epoch 16/80\n",
      "27/27 - 145s - loss: 0.2429 - accuracy: 0.9078 - val_loss: 0.4825 - val_accuracy: 0.8212 - 145s/epoch - 5s/step\n",
      "Epoch 17/80\n",
      "27/27 - 142s - loss: 0.2554 - accuracy: 0.9090 - val_loss: 0.4258 - val_accuracy: 0.8403 - 142s/epoch - 5s/step\n",
      "Epoch 18/80\n",
      "27/27 - 141s - loss: 0.2447 - accuracy: 0.9032 - val_loss: 0.4069 - val_accuracy: 0.8472 - 141s/epoch - 5s/step\n",
      "Epoch 19/80\n",
      "27/27 - 141s - loss: 0.2311 - accuracy: 0.9084 - val_loss: 0.3606 - val_accuracy: 0.8646 - 141s/epoch - 5s/step\n",
      "Epoch 20/80\n",
      "27/27 - 138s - loss: 0.2269 - accuracy: 0.9043 - val_loss: 0.9662 - val_accuracy: 0.7847 - 138s/epoch - 5s/step\n",
      "Epoch 21/80\n",
      "27/27 - 134s - loss: 0.2372 - accuracy: 0.9014 - val_loss: 0.4461 - val_accuracy: 0.8455 - 134s/epoch - 5s/step\n",
      "Epoch 22/80\n",
      "27/27 - 134s - loss: 0.2090 - accuracy: 0.9188 - val_loss: 0.4884 - val_accuracy: 0.8490 - 134s/epoch - 5s/step\n",
      "Epoch 23/80\n",
      "27/27 - 134s - loss: 0.2093 - accuracy: 0.9038 - val_loss: 0.3725 - val_accuracy: 0.8715 - 134s/epoch - 5s/step\n",
      "Epoch 24/80\n",
      "27/27 - 134s - loss: 0.1926 - accuracy: 0.9252 - val_loss: 0.6911 - val_accuracy: 0.8594 - 134s/epoch - 5s/step\n",
      "Epoch 25/80\n",
      "27/27 - 136s - loss: 0.2179 - accuracy: 0.9119 - val_loss: 0.4155 - val_accuracy: 0.8559 - 136s/epoch - 5s/step\n",
      "Epoch 26/80\n",
      "27/27 - 133s - loss: 0.2683 - accuracy: 0.8957 - val_loss: 1.5769 - val_accuracy: 0.7691 - 133s/epoch - 5s/step\n",
      "Epoch 27/80\n",
      "27/27 - 133s - loss: 0.1891 - accuracy: 0.9270 - val_loss: 1.3940 - val_accuracy: 0.8316 - 133s/epoch - 5s/step\n",
      "Epoch 28/80\n",
      "27/27 - 133s - loss: 0.2232 - accuracy: 0.9096 - val_loss: 0.7204 - val_accuracy: 0.8247 - 133s/epoch - 5s/step\n",
      "Epoch 29/80\n",
      "27/27 - 133s - loss: 0.2581 - accuracy: 0.9026 - val_loss: 2.0854 - val_accuracy: 0.7865 - 133s/epoch - 5s/step\n",
      "Epoch 30/80\n",
      "27/27 - 133s - loss: 0.2043 - accuracy: 0.9287 - val_loss: 0.7707 - val_accuracy: 0.8281 - 133s/epoch - 5s/step\n",
      "Epoch 31/80\n",
      "27/27 - 134s - loss: 0.1789 - accuracy: 0.9281 - val_loss: 0.7155 - val_accuracy: 0.8385 - 134s/epoch - 5s/step\n",
      "Epoch 32/80\n",
      "27/27 - 132s - loss: 0.1791 - accuracy: 0.9299 - val_loss: 0.8232 - val_accuracy: 0.8212 - 132s/epoch - 5s/step\n",
      "Epoch 33/80\n",
      "27/27 - 135s - loss: 0.1941 - accuracy: 0.9217 - val_loss: 0.5659 - val_accuracy: 0.8611 - 135s/epoch - 5s/step\n",
      "Epoch 34/80\n",
      "27/27 - 137s - loss: 0.1760 - accuracy: 0.9339 - val_loss: 0.8472 - val_accuracy: 0.8160 - 137s/epoch - 5s/step\n",
      "Epoch 35/80\n",
      "27/27 - 138s - loss: 0.2034 - accuracy: 0.9212 - val_loss: 0.7504 - val_accuracy: 0.7378 - 138s/epoch - 5s/step\n",
      "Epoch 36/80\n",
      "27/27 - 137s - loss: 0.1945 - accuracy: 0.9165 - val_loss: 0.5645 - val_accuracy: 0.8316 - 137s/epoch - 5s/step\n",
      "Epoch 37/80\n",
      "27/27 - 140s - loss: 0.1472 - accuracy: 0.9472 - val_loss: 0.5589 - val_accuracy: 0.8247 - 140s/epoch - 5s/step\n",
      "Epoch 38/80\n",
      "27/27 - 137s - loss: 0.1639 - accuracy: 0.9357 - val_loss: 1.0405 - val_accuracy: 0.7934 - 137s/epoch - 5s/step\n",
      "Epoch 39/80\n",
      "27/27 - 137s - loss: 0.1678 - accuracy: 0.9293 - val_loss: 0.8140 - val_accuracy: 0.8316 - 137s/epoch - 5s/step\n",
      "Epoch 40/80\n",
      "27/27 - 138s - loss: 0.1521 - accuracy: 0.9443 - val_loss: 0.8907 - val_accuracy: 0.8351 - 138s/epoch - 5s/step\n",
      "Epoch 41/80\n",
      "27/27 - 137s - loss: 0.1324 - accuracy: 0.9519 - val_loss: 1.0945 - val_accuracy: 0.8385 - 137s/epoch - 5s/step\n",
      "Epoch 42/80\n",
      "27/27 - 138s - loss: 0.1826 - accuracy: 0.9322 - val_loss: 0.7223 - val_accuracy: 0.8038 - 138s/epoch - 5s/step\n",
      "Epoch 43/80\n",
      "27/27 - 137s - loss: 0.1414 - accuracy: 0.9409 - val_loss: 0.4666 - val_accuracy: 0.8524 - 137s/epoch - 5s/step\n",
      "Epoch 44/80\n",
      "27/27 - 137s - loss: 0.1394 - accuracy: 0.9484 - val_loss: 0.7335 - val_accuracy: 0.8733 - 137s/epoch - 5s/step\n",
      "Epoch 45/80\n",
      "27/27 - 136s - loss: 0.1462 - accuracy: 0.9397 - val_loss: 0.4744 - val_accuracy: 0.8559 - 136s/epoch - 5s/step\n",
      "Epoch 46/80\n",
      "27/27 - 137s - loss: 0.1604 - accuracy: 0.9357 - val_loss: 2.8594 - val_accuracy: 0.8021 - 137s/epoch - 5s/step\n",
      "Epoch 47/80\n",
      "27/27 - 137s - loss: 0.1331 - accuracy: 0.9484 - val_loss: 0.6113 - val_accuracy: 0.7951 - 137s/epoch - 5s/step\n",
      "Epoch 48/80\n",
      "27/27 - 138s - loss: 0.1378 - accuracy: 0.9467 - val_loss: 2.6663 - val_accuracy: 0.8125 - 138s/epoch - 5s/step\n",
      "Epoch 49/80\n",
      "27/27 - 138s - loss: 0.1541 - accuracy: 0.9374 - val_loss: 1.9737 - val_accuracy: 0.8212 - 138s/epoch - 5s/step\n",
      "Epoch 50/80\n",
      "27/27 - 139s - loss: 0.1166 - accuracy: 0.9542 - val_loss: 2.3766 - val_accuracy: 0.8316 - 139s/epoch - 5s/step\n",
      "Epoch 51/80\n",
      "27/27 - 138s - loss: 0.1453 - accuracy: 0.9513 - val_loss: 0.4375 - val_accuracy: 0.8438 - 138s/epoch - 5s/step\n",
      "Epoch 52/80\n",
      "27/27 - 138s - loss: 0.1198 - accuracy: 0.9501 - val_loss: 0.6310 - val_accuracy: 0.8507 - 138s/epoch - 5s/step\n",
      "Epoch 53/80\n",
      "27/27 - 138s - loss: 0.1336 - accuracy: 0.9536 - val_loss: 0.9449 - val_accuracy: 0.8681 - 138s/epoch - 5s/step\n",
      "Epoch 54/80\n",
      "27/27 - 139s - loss: 0.1154 - accuracy: 0.9461 - val_loss: 0.7295 - val_accuracy: 0.8472 - 139s/epoch - 5s/step\n",
      "Epoch 55/80\n",
      "27/27 - 139s - loss: 0.0805 - accuracy: 0.9658 - val_loss: 0.5408 - val_accuracy: 0.8767 - 139s/epoch - 5s/step\n",
      "Epoch 56/80\n",
      "27/27 - 139s - loss: 0.0857 - accuracy: 0.9687 - val_loss: 0.7199 - val_accuracy: 0.8733 - 139s/epoch - 5s/step\n",
      "Epoch 57/80\n",
      "27/27 - 139s - loss: 0.1495 - accuracy: 0.9409 - val_loss: 0.7114 - val_accuracy: 0.8594 - 139s/epoch - 5s/step\n",
      "Epoch 58/80\n",
      "27/27 - 140s - loss: 0.1568 - accuracy: 0.9386 - val_loss: 0.8399 - val_accuracy: 0.8403 - 140s/epoch - 5s/step\n",
      "Epoch 59/80\n",
      "27/27 - 139s - loss: 0.1028 - accuracy: 0.9600 - val_loss: 0.7928 - val_accuracy: 0.8576 - 139s/epoch - 5s/step\n",
      "Epoch 60/80\n",
      "27/27 - 141s - loss: 0.0999 - accuracy: 0.9629 - val_loss: 0.9115 - val_accuracy: 0.8524 - 141s/epoch - 5s/step\n",
      "Epoch 61/80\n",
      "27/27 - 139s - loss: 0.1524 - accuracy: 0.9449 - val_loss: 1.8140 - val_accuracy: 0.8142 - 139s/epoch - 5s/step\n",
      "Epoch 62/80\n",
      "27/27 - 140s - loss: 0.1307 - accuracy: 0.9455 - val_loss: 0.7595 - val_accuracy: 0.8490 - 140s/epoch - 5s/step\n",
      "Epoch 63/80\n",
      "27/27 - 139s - loss: 0.1169 - accuracy: 0.9664 - val_loss: 0.9274 - val_accuracy: 0.8472 - 139s/epoch - 5s/step\n",
      "Epoch 64/80\n",
      "27/27 - 138s - loss: 0.1277 - accuracy: 0.9478 - val_loss: 1.6173 - val_accuracy: 0.8281 - 138s/epoch - 5s/step\n",
      "Epoch 65/80\n",
      "27/27 - 140s - loss: 0.1334 - accuracy: 0.9496 - val_loss: 1.2130 - val_accuracy: 0.8472 - 140s/epoch - 5s/step\n",
      "Epoch 66/80\n",
      "27/27 - 138s - loss: 0.0739 - accuracy: 0.9716 - val_loss: 0.5132 - val_accuracy: 0.8663 - 138s/epoch - 5s/step\n",
      "Epoch 67/80\n",
      "27/27 - 141s - loss: 0.1412 - accuracy: 0.9443 - val_loss: 0.5657 - val_accuracy: 0.8646 - 141s/epoch - 5s/step\n",
      "Epoch 68/80\n",
      "27/27 - 138s - loss: 0.1014 - accuracy: 0.9588 - val_loss: 0.7809 - val_accuracy: 0.8038 - 138s/epoch - 5s/step\n",
      "Epoch 69/80\n",
      "27/27 - 141s - loss: 0.1066 - accuracy: 0.9559 - val_loss: 0.9277 - val_accuracy: 0.7969 - 141s/epoch - 5s/step\n",
      "Epoch 70/80\n",
      "27/27 - 139s - loss: 0.0955 - accuracy: 0.9635 - val_loss: 0.7122 - val_accuracy: 0.8490 - 139s/epoch - 5s/step\n",
      "Epoch 71/80\n",
      "27/27 - 140s - loss: 0.0916 - accuracy: 0.9658 - val_loss: 0.5856 - val_accuracy: 0.8264 - 140s/epoch - 5s/step\n",
      "Epoch 72/80\n",
      "27/27 - 139s - loss: 0.1223 - accuracy: 0.9530 - val_loss: 0.7930 - val_accuracy: 0.8385 - 139s/epoch - 5s/step\n",
      "Epoch 73/80\n",
      "27/27 - 140s - loss: 0.0916 - accuracy: 0.9658 - val_loss: 0.9037 - val_accuracy: 0.8090 - 140s/epoch - 5s/step\n",
      "Epoch 74/80\n",
      "27/27 - 142s - loss: 0.0738 - accuracy: 0.9704 - val_loss: 0.6541 - val_accuracy: 0.8733 - 142s/epoch - 5s/step\n",
      "Epoch 75/80\n",
      "27/27 - 141s - loss: 0.0652 - accuracy: 0.9768 - val_loss: 0.8666 - val_accuracy: 0.8507 - 141s/epoch - 5s/step\n",
      "Epoch 76/80\n",
      "27/27 - 138s - loss: 0.1050 - accuracy: 0.9670 - val_loss: 0.6245 - val_accuracy: 0.8594 - 138s/epoch - 5s/step\n",
      "Epoch 77/80\n",
      "27/27 - 139s - loss: 0.0923 - accuracy: 0.9664 - val_loss: 1.0625 - val_accuracy: 0.8090 - 139s/epoch - 5s/step\n",
      "Epoch 78/80\n",
      "27/27 - 137s - loss: 0.0588 - accuracy: 0.9757 - val_loss: 0.8917 - val_accuracy: 0.8403 - 137s/epoch - 5s/step\n",
      "Epoch 79/80\n",
      "27/27 - 140s - loss: 0.0677 - accuracy: 0.9751 - val_loss: 0.6517 - val_accuracy: 0.8767 - 140s/epoch - 5s/step\n",
      "Epoch 80/80\n",
      "27/27 - 137s - loss: 0.0980 - accuracy: 0.9600 - val_loss: 0.7844 - val_accuracy: 0.8663 - 137s/epoch - 5s/step\n"
     ]
    }
   ],
   "source": [
    "adam = Adam(lr=0.001)\n",
    "model.compile(optimizer=adam, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "history = model.fit(x_train, y_train, batch_size=64, epochs=80, verbose=2, validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "laden-alert",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights(\"model_coffe_1.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "canadian-bench",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "27/27 - 151s - loss: 0.0877 - accuracy: 0.9693 - val_loss: 1.8560 - val_accuracy: 0.8628 - 151s/epoch - 6s/step\n",
      "Epoch 2/10\n",
      "27/27 - 137s - loss: 0.0836 - accuracy: 0.9687 - val_loss: 0.9785 - val_accuracy: 0.8576 - 137s/epoch - 5s/step\n",
      "Epoch 3/10\n",
      "27/27 - 142s - loss: 0.0670 - accuracy: 0.9791 - val_loss: 1.1743 - val_accuracy: 0.8351 - 142s/epoch - 5s/step\n",
      "Epoch 4/10\n",
      "27/27 - 138s - loss: 0.0430 - accuracy: 0.9838 - val_loss: 0.8105 - val_accuracy: 0.8698 - 138s/epoch - 5s/step\n",
      "Epoch 5/10\n",
      "27/27 - 139s - loss: 0.0443 - accuracy: 0.9809 - val_loss: 0.7673 - val_accuracy: 0.8819 - 139s/epoch - 5s/step\n",
      "Epoch 6/10\n",
      "27/27 - 140s - loss: 0.0372 - accuracy: 0.9896 - val_loss: 0.8186 - val_accuracy: 0.8559 - 140s/epoch - 5s/step\n",
      "Epoch 7/10\n",
      "27/27 - 140s - loss: 0.0580 - accuracy: 0.9774 - val_loss: 0.8456 - val_accuracy: 0.8733 - 140s/epoch - 5s/step\n",
      "Epoch 8/10\n",
      "27/27 - 139s - loss: 0.0643 - accuracy: 0.9768 - val_loss: 0.7691 - val_accuracy: 0.8750 - 139s/epoch - 5s/step\n",
      "Epoch 9/10\n",
      "27/27 - 136s - loss: 0.0564 - accuracy: 0.9814 - val_loss: 3.7392 - val_accuracy: 0.8646 - 136s/epoch - 5s/step\n",
      "Epoch 10/10\n",
      "27/27 - 120s - loss: 0.0444 - accuracy: 0.9843 - val_loss: 2.0847 - val_accuracy: 0.8681 - 120s/epoch - 4s/step\n"
     ]
    }
   ],
   "source": [
    "adam = Adam(lr=0.0005)\n",
    "model.compile(optimizer=adam, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "history = model.fit(x_train, y_train, batch_size=64, epochs=10, verbose=2, validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "confident-cliff",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights(\"model_coffe_12.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "twenty-straight",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "27/27 - 128s - loss: 0.0694 - accuracy: 0.9820 - val_loss: 3.3979 - val_accuracy: 0.8594 - 128s/epoch - 5s/step\n",
      "Epoch 2/10\n",
      "27/27 - 121s - loss: 0.0663 - accuracy: 0.9768 - val_loss: 0.9044 - val_accuracy: 0.8559 - 121s/epoch - 4s/step\n",
      "Epoch 3/10\n",
      "27/27 - 121s - loss: 0.0682 - accuracy: 0.9728 - val_loss: 0.6035 - val_accuracy: 0.8819 - 121s/epoch - 4s/step\n",
      "Epoch 4/10\n",
      "27/27 - 121s - loss: 0.0281 - accuracy: 0.9907 - val_loss: 0.6881 - val_accuracy: 0.8924 - 121s/epoch - 4s/step\n",
      "Epoch 5/10\n",
      "27/27 - 121s - loss: 0.0302 - accuracy: 0.9907 - val_loss: 1.4757 - val_accuracy: 0.8733 - 121s/epoch - 4s/step\n",
      "Epoch 6/10\n",
      "27/27 - 121s - loss: 0.0610 - accuracy: 0.9803 - val_loss: 0.7520 - val_accuracy: 0.8854 - 121s/epoch - 4s/step\n",
      "Epoch 7/10\n",
      "27/27 - 122s - loss: 0.0390 - accuracy: 0.9861 - val_loss: 0.7440 - val_accuracy: 0.8750 - 122s/epoch - 5s/step\n",
      "Epoch 8/10\n",
      "27/27 - 122s - loss: 0.0284 - accuracy: 0.9925 - val_loss: 1.1672 - val_accuracy: 0.8576 - 122s/epoch - 5s/step\n",
      "Epoch 9/10\n",
      "27/27 - 122s - loss: 0.0332 - accuracy: 0.9907 - val_loss: 0.6511 - val_accuracy: 0.8785 - 122s/epoch - 5s/step\n",
      "Epoch 10/10\n",
      "27/27 - 122s - loss: 0.0143 - accuracy: 0.9959 - val_loss: 0.9126 - val_accuracy: 0.8663 - 122s/epoch - 5s/step\n"
     ]
    }
   ],
   "source": [
    "adam = Adam(lr=0.0005)\n",
    "model.compile(optimizer=adam, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "history = model.fit(x_train, y_train, batch_size=64, epochs=10, verbose=2, validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "recreational-domain",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights(\"model_coffe_13.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "clinical-quick",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 9s 347ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = np.argmax(model.predict(x_test), axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "soviet-neighborhood",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model predication accuracy: 0.904\n",
      "\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.88      0.91       297\n",
      "           1       0.88      0.93      0.90       278\n",
      "\n",
      "    accuracy                           0.90       575\n",
      "   macro avg       0.90      0.91      0.90       575\n",
      "weighted avg       0.91      0.90      0.90       575\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_test = np.nonzero(y_test)[1]\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Model predication accuracy: {accuracy:.3f}')\n",
    "print(f'\\nClassification report:\\n {classification_report(y_test, y_pred)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "transsexual-hormone",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3.8.3",
   "language": "python",
   "name": "python3.8.3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
