{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "upset-stone",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from skimage.io import imread, imsave\n",
    "\n",
    "from keras import applications\n",
    "from keras import optimizers\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Activation, Dense, Dropout, Flatten, GlobalAveragePooling2D\n",
    "from keras.utils import to_categorical\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "from sklearn.metrics import fbeta_score, precision_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import cv2\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "primary-sauce",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_dir = os.path.join('train-jpg', 'train-jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "passive-reception",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['blooming', 'haze', 'clear', 'water', 'primary', 'cultivation', 'selective_logging', 'blow_down', 'agriculture', 'habitation', 'slash_burn', 'bare_ground', 'road', 'conventional_mine', 'artisinal_mine', 'partly_cloudy']\n",
      "(31129, 139, 139, 3)\n",
      "(31129, 15)\n"
     ]
    }
   ],
   "source": [
    "x_train = []\n",
    "y_train = []\n",
    "\n",
    "train_data = pd.read_csv('train_v2.csv/train_v2.csv')\n",
    "\n",
    "label_enum = 0\n",
    "label_map = {}\n",
    "labels = {}\n",
    "for tags in train_data['tags']:\n",
    "    classes = tags.split(\" \")\n",
    "    for label in classes:\n",
    "        if label not in label_map and label != \"cloudy\" and label != \"partly_cloudy\":\n",
    "            label_map[label] = label_enum\n",
    "            labels[label_enum] = label\n",
    "            label_enum = label_enum + 1\n",
    "    if label_enum == 17:\n",
    "        break\n",
    "\n",
    "for image, tags in train_data.values:\n",
    "    image_path = source_dir+\"/\"+image+\".jpg\"\n",
    "    img = cv2.imread(image_path)\n",
    "    img = cv2.resize(img, (139, 139))\n",
    "    one_hot_labels = np.zeros(len(label_map))\n",
    "    cloudy = False\n",
    "    for label in tags.split(' '):\n",
    "        if label == \"cloudy\" or label == \"partly_cloudy\":\n",
    "            cloudy = True\n",
    "        else:\n",
    "            one_hot_labels[label_map[label]] = 1\n",
    "    if not cloudy:\n",
    "        x_train.append(img/255.0)\n",
    "        y_train.append(one_hot_labels)\n",
    "    \n",
    "y_train = np.array(y_train, np.uint8)\n",
    "x_train = np.array(x_train, np.float32)\n",
    "\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "informational-chicago",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size =0.2)\n",
    "x_test, x_val, y_test, y_val = train_test_split(x_val, y_val, test_size =0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "national-james",
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_model = applications.InceptionV3(include_top=False, weights='imagenet', input_shape = (139, 139, 3))\n",
    "pretrained_model.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "synthetic-guitar",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_layer = pretrained_model.input\n",
    "model_output = pretrained_model.output\n",
    "pooling_layer = GlobalAveragePooling2D()(model_output)\n",
    "dense_layer = Dense(2048, activation='relu')(pooling_layer)\n",
    "dropout_layer = Dropout(0.5)(dense_layer)\n",
    "output_layer = Dense(17, activation='sigmoid')(dropout_layer)\n",
    "model = Model(inputs=input_layer, outputs=output_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "continued-sellers",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "195/195 - 70s - loss: 0.1541 - accuracy: 0.2131 - val_loss: 0.1302 - val_accuracy: 0.0694 - 70s/epoch - 361ms/step\n",
      "Epoch 2/5\n",
      "195/195 - 65s - loss: 0.1224 - accuracy: 0.2196 - val_loss: 0.1292 - val_accuracy: 0.5149 - 65s/epoch - 333ms/step\n",
      "Epoch 3/5\n",
      "195/195 - 65s - loss: 0.1157 - accuracy: 0.2187 - val_loss: 0.1246 - val_accuracy: 0.1362 - 65s/epoch - 332ms/step\n",
      "Epoch 4/5\n",
      "195/195 - 65s - loss: 0.1108 - accuracy: 0.2124 - val_loss: 0.1248 - val_accuracy: 0.1580 - 65s/epoch - 332ms/step\n",
      "Epoch 5/5\n",
      "195/195 - 65s - loss: 0.1056 - accuracy: 0.2159 - val_loss: 0.1238 - val_accuracy: 0.1474 - 65s/epoch - 333ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2b8e3c66f550>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer = Adam()\n",
    "model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "history = model.fit(x_train, y_train, validation_data=(x_val, y_val), batch_size=128,verbose=2, epochs=10, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mighty-bunch",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('model_cloudy_final.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "above-startup",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_accuracy = history.history['accuracy']\n",
    "val_accuracy = history.history['val_accuracy']\n",
    "train_loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(len(train_accuracy))\n",
    "\n",
    "plt.plot(epochs, train_accuracy, 'r', label='Training accuracy')\n",
    "plt.plot(epochs, val_accuracy, 'b', label='Validation accuracy')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend(loc=0)\n",
    "plt.figure()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adaptive-incentive",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(epochs, train_loss, 'r', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend(loc=0)\n",
    "plt.figure()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "located-custom",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 - 8s - 8s/epoch - 328ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(x_test, batch_size = 128, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "veterinary-twenty",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F2 score: 0.918115579677878\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import fbeta_score, precision_score \n",
    "print(\"F2 score:\",fbeta_score(y_test, np.array(y_pred)>0.2, beta=2, average='samples'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "arabic-married",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = np.array(y_pred)>0.2\n",
    "total = np.sum(y_test,axis = 0)\n",
    "tp = np.sum(y_test*y_pred,axis=0)\n",
    "tn = np.sum((1-y_test)*(1-y_pred),axis=0)\n",
    "fp = np.sum((1-y_test)*y_pred,axis=0)\n",
    "fn = np.sum(y_test*(1-y_pred),axis=0)\n",
    "\n",
    "d = {'Total':total,'TP':tp,'TN':tn,'FP':fp,'FN':fn}\n",
    "pd.DataFrame(d, index=label_map)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "brief-certification",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum = np.add(tp, fp)\n",
    "precision = np.divide(tp, sum)\n",
    "recall = np.divide(tp, np.add(tp, fn))\n",
    "accuracy = np.divide(np.add(tp, tn), np.add(fp, np.add(fn, np.add(tp, tn))))\n",
    "f1 = 2*(np.divide(np.multiply(precision, recall), np.add(precision, recall)))\n",
    "f2 = (np.divide(5*np.multiply(precision, recall), np.add(4*precision, recall)))\n",
    "evalution_metrics = {'Accuracy':accuracy,'Precision':precision,'Recall':recall,'f1':f1, 'f2': f2}\n",
    "pd.DataFrame(evalution_metrics, index=label_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "casual-encounter",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3.8.3",
   "language": "python",
   "name": "python3.8.3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
